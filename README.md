Sure, here are the main points from the above code that you can add to your resume:

1. Developed a **web scraper** using Python's **BeautifulSoup** and **requests** libraries.
2. The scraper takes a **target URL** as input and uses a **deque** data structure to manage URLs for scraping.
3. Implemented a mechanism to avoid scraping the same URL multiple times using a **set** data structure.
4. The scraper can handle up to **100 URLs** in a single run, ensuring efficient use of resources.
5. Used Python's built-in **urllib.parse** library to split the URL into components and manage relative and absolute URLs.
6. Utilized **regular expressions (re)** to find all email addresses present in the text of each webpage.
7. The scraper is capable of finding and following all links present on a webpage using BeautifulSoup's `find_all` method.
8. Implemented error handling for exceptions raised during requests, ensuring the scraper continues running even if it encounters a problematic URL.
9. The program gracefully handles keyboard interrupts, allowing the user to stop the program at any time.
10. At the end of its run, the scraper prints out all unique email addresses it has found.

This project demonstrates your skills in web scraping, regular expressions, error handling, and data structure management in Python. It shows that you can build a robust and efficient web scraper that respects resource limitations and handles errors gracefully. It also highlights your ability to work with relative and absolute URLs and find specific patterns in text using regular expressions.
